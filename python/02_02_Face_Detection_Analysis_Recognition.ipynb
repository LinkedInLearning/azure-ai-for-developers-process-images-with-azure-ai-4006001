{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection, Face Analysis, Face Recognition\n",
    "\n",
    "Requirements: Azure AI Face Resource\n",
    "\n",
    "Face detection and analysis: Detect human faces in an image and return the rectangle coordinates of their locations, and optionally with landmarks, and face-related attributes. This operation is required as a first step in all the other face recognition scenarios.\n",
    "\n",
    "Face recognition: Confirm that a user is who they claim to be based on how closely their face data matches the target face. It includes Face verification (\"one-to-one\" matching).\n",
    "\n",
    "Business Case:\n",
    "Building Security where employee faces are saved into the system\n",
    "\n",
    "Determine Input Requirements:\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/overview-identity#input-requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade azure-ai-vision-face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "azure_face_endpoint = os.environ[\"AZURE_FACE_ENDPOINT\"]\n",
    "azure_face_key = os.environ[\"AZURE_FACE_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Clients\n",
    "\n",
    "https://learn.microsoft.com/en-us/python/api/overview/azure/ai-vision-face-readme?view=azure-python-preview#key-concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.vision.face import FaceAdministrationClient, FaceClient\n",
    "from azure.ai.vision.face.models import FaceAttributeTypeRecognition04, FaceDetectionModel, FaceRecognitionModel, QualityForRecognition,  FaceAttributeTypeDetection03\n",
    "\n",
    "face_admin_client = FaceAdministrationClient(endpoint=azure_face_endpoint, credential=AzureKeyCredential(azure_face_key))\n",
    "face_client = FaceClient(endpoint=azure_face_endpoint, credential=AzureKeyCredential(azure_face_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the file content of the image in the specified path\n",
    "def read_file_content(file_path: str):\n",
    "    with open(file_path, \"rb\") as fd:\n",
    "        file_content = fd.read()\n",
    "    return file_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect and Analyze Faces\n",
    "\n",
    "Detects the face and its attributes \n",
    "\n",
    "Detection and Recognition Model Definitions: https://learn.microsoft.com/en-us/python/api/azure-ai-vision-face/azure.ai.vision.face.faceclient?view=azure-python-preview#azure-ai-vision-face-faceclient-detect\n",
    "\n",
    "Face Attributes: https://learn.microsoft.com/en-us/python/api/azure-ai-vision-face/azure.ai.vision.face.models.faceattributetype?view=azure-python-preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = \"../data/face/group/group_1.jpeg\"\n",
    "\n",
    "file_content = read_file_content(sample_file_path)\n",
    "\n",
    "result = face_client.detect(\n",
    "    file_content,\n",
    "    detection_model=FaceDetectionModel.DETECTION03,  # The latest detection model.\n",
    "    recognition_model=FaceRecognitionModel.RECOGNITION04,  # The latest recognition model.\n",
    "    return_face_id=True,\n",
    "    return_face_attributes=[\n",
    "        FaceAttributeTypeDetection03.HEAD_POSE,\n",
    "        FaceAttributeTypeDetection03.MASK,\n",
    "        FaceAttributeTypeRecognition04.QUALITY_FOR_RECOGNITION,\n",
    "    ],\n",
    "    return_face_landmarks=True,\n",
    "    return_recognition_model=True,\n",
    "    face_id_time_to_live=120,\n",
    ")\n",
    "\n",
    "print(f\"Detect faces from the file: {sample_file_path}\")\n",
    "# Print all detection results per line\n",
    "for face in result:\n",
    "    print(f\"Face ID: {face.face_id}\")\n",
    "    print(f\"Face Rectangle: {face.face_rectangle.as_dict()}\")\n",
    "    print(f\"Face Landmarks:\")\n",
    "    for landmark, position in face.face_landmarks.as_dict().items():\n",
    "        print(f\"  {landmark}: {position}\")\n",
    "    print(f\"Face Attributes: {face.face_attributes.as_dict()}\")\n",
    "    print(f\"Recognition Model: {face.recognition_model}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the face bounding box and the landmark points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "image = Image.open(sample_file_path)\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "for idx, face in enumerate(result):\n",
    "    # Draw bounding box\n",
    "    rect = face.face_rectangle\n",
    "    left = rect.left\n",
    "    top = rect.top\n",
    "    right = left + rect.width\n",
    "    bottom = top + rect.height\n",
    "    draw.rectangle([left, top, right, bottom], outline=\"red\", width=3)\n",
    "    \n",
    "    # Draw landmarks\n",
    "    for landmark in face.face_landmarks.as_dict().values():\n",
    "        x, y = landmark['x'], landmark['y']\n",
    "        draw.ellipse((x-2, y-2, x+2, y+2), fill=\"blue\")\n",
    "\n",
    "# Save or display the image with bounding boxes and landmarks\n",
    "#output_path = \"../Data/images/group/group_1_with_boxes_and_landmarks.jpg\"\n",
    "#image.save(output_path)\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Large Person Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used in the Large Person Group Operations and Delete Large Person Group examples.\n",
    "# LARGE_PERSON_GROUP_ID should be all lowercase and alphanumeric. For example, 'mygroupname' (dashes are OK).\n",
    "LARGE_PERSON_GROUP_ID = str(uuid.uuid4())  # assign a random ID (or name it anything)\n",
    "\n",
    "# Create a Large Person Group\n",
    "print(\"Person group:\", LARGE_PERSON_GROUP_ID)\n",
    "face_admin_client.large_person_group.create(\n",
    "    large_person_group_id=LARGE_PERSON_GROUP_ID,\n",
    "    name=LARGE_PERSON_GROUP_ID,\n",
    "    recognition_model=FaceRecognitionModel.RECOGNITION04,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Persons to Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define person\n",
    "person_A = face_admin_client.large_person_group.create_person(\n",
    "    large_person_group_id=LARGE_PERSON_GROUP_ID,\n",
    "    name=\"Person A\",\n",
    ")\n",
    "\n",
    "# Images\n",
    "person_A_image_file_path = [\n",
    "    \"../data/face/person_a/person_a1.jpeg\",\n",
    "    \"../data/face/person_a/person_a2.jpeg\",\n",
    "]\n",
    "\n",
    "for image in person_A_image_file_path:\n",
    "    # Read the image file\n",
    "    file_content = read_file_content(image)\n",
    "\n",
    "    # Detect the face \n",
    "    result = face_client.detect(\n",
    "        file_content,\n",
    "        detection_model=FaceDetectionModel.DETECTION03,  # The latest detection model.\n",
    "        recognition_model=FaceRecognitionModel.RECOGNITION04,  # The latest recognition model.\n",
    "        return_face_id=True,\n",
    "        return_face_attributes=[FaceAttributeTypeRecognition04.QUALITY_FOR_RECOGNITION]\n",
    "    )\n",
    "\n",
    "    # Ensure only one face is detected and it has high quality for recognition\n",
    "    if len(result) == 1 and result[0].face_attributes.quality_for_recognition == QualityForRecognition.HIGH:\n",
    "        face_admin_client.large_person_group.add_face(\n",
    "            LARGE_PERSON_GROUP_ID,\n",
    "            person_A.person_id,\n",
    "            file_content,\n",
    "            detection_model=FaceDetectionModel.DETECTION03,        \n",
    "    )\n",
    "        \n",
    "    print(f\"Face {result[0].face_id} added to person {person_A.person_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define person\n",
    "person_B = face_admin_client.large_person_group.create_person(\n",
    "    large_person_group_id=LARGE_PERSON_GROUP_ID,\n",
    "    name=\"Person B\",\n",
    ")\n",
    "\n",
    "# Images\n",
    "person_B_image_file_path = [\n",
    "    \"../data/face/person_b/person_b1.jpeg\",\n",
    "    \"../data/face/person_b/person_b2.jpeg\",\n",
    "]\n",
    "\n",
    "for image in person_B_image_file_path:\n",
    "    # Read the image file\n",
    "    file_content = read_file_content(image)\n",
    "\n",
    "    # Detect the face \n",
    "    result = face_client.detect(\n",
    "        file_content,\n",
    "        detection_model=FaceDetectionModel.DETECTION03,  # The latest detection model.\n",
    "        recognition_model=FaceRecognitionModel.RECOGNITION04,  # The latest recognition model.\n",
    "        return_face_id=True,\n",
    "        return_face_attributes=[FaceAttributeTypeRecognition04.QUALITY_FOR_RECOGNITION]\n",
    "    )\n",
    "\n",
    "    # Ensure only one face is detected and it has high quality for recognition\n",
    "    if len(result) == 1 and result[0].face_attributes.quality_for_recognition == QualityForRecognition.HIGH:\n",
    "        face_admin_client.large_person_group.add_face(\n",
    "            LARGE_PERSON_GROUP_ID,\n",
    "            person_B.person_id,\n",
    "            file_content,\n",
    "            detection_model=FaceDetectionModel.DETECTION03,        \n",
    "    )\n",
    "        \n",
    "    print(f\"Face {result[0].face_id} added to person {person_B.person_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Large Person Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the large person group and set the polling interval to 5s\n",
    "print(f\"Train the person group {LARGE_PERSON_GROUP_ID}\")\n",
    "poller = face_admin_client.large_person_group.begin_train(\n",
    "    large_person_group_id=LARGE_PERSON_GROUP_ID,\n",
    "    polling_interval=5,\n",
    ")\n",
    "\n",
    "poller.wait()\n",
    "print(f\"The person group {LARGE_PERSON_GROUP_ID} is trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Faces in NEW Images and Determine their Identity in Large Person Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image for testing against\n",
    "image=\"../data/face/group/group_2.jpeg\"\n",
    "file_content = read_file_content(image)\n",
    "\n",
    "# Face IDs collection for all detected faces that are of sufficient quality for recognition\n",
    "face_ids = []\n",
    "\n",
    "# We use detection model 03 to get better performance, recognition model 04 to support quality for recognition attribute.\n",
    "# Check if the image is of sufficient quality for recognition.\n",
    "faces = face_client.detect(\n",
    "    file_content,\n",
    "    detection_model=FaceDetectionModel.DETECTION03,  # The latest detection model.\n",
    "    recognition_model=FaceRecognitionModel.RECOGNITION04,  # The latest recognition model.\n",
    "    return_face_id=True,\n",
    "    return_face_attributes=[FaceAttributeTypeRecognition04.QUALITY_FOR_RECOGNITION]\n",
    ")\n",
    "\n",
    "for face in faces:\n",
    "    # Only take the face if it is of sufficient quality.\n",
    "    if face.face_attributes.quality_for_recognition != QualityForRecognition.LOW:\n",
    "        face_ids.append(face.face_id)\n",
    "\n",
    "# Identify faces\n",
    "identify_results = face_client.identify_from_large_person_group(\n",
    "    face_ids=face_ids,\n",
    "    large_person_group_id=LARGE_PERSON_GROUP_ID,\n",
    ")\n",
    "print(\"Identifying faces in image\")\n",
    "for identify_result in identify_results:\n",
    "    if identify_result.candidates:\n",
    "        print(f\"Person is identified for face ID {identify_result.face_id} in image, with a confidence of \"\n",
    "              f\"{identify_result.candidates[0].confidence}.\")  # Get topmost confidence score\n",
    "\n",
    "    # Verify faces\n",
    "        verify_result = face_client.verify_from_large_person_group(\n",
    "            face_id=identify_result.face_id,\n",
    "            large_person_group_id=LARGE_PERSON_GROUP_ID,\n",
    "            person_id=identify_result.candidates[0].person_id,\n",
    "        )\n",
    "        print(f\"Person Identified: {identify_result.candidates[0].person_id}. Verification result: {verify_result.is_identical}. confidence: {verify_result.confidence}\")\n",
    "    else:\n",
    "        print(f\"No person identified for face ID {identify_result.face_id} in image.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] Identify Faces in Images and place bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Group image for testing against\n",
    "image_path = \"../data/face/group/group_2.jpeg\"\n",
    "file_content = read_file_content(image_path)\n",
    "\n",
    "# Detect faces\n",
    "face_ids = []\n",
    "face_rectangles = {}\n",
    "# We use detection model 03 to get better performance, recognition model 04 to support quality for recognition attribute.\n",
    "# Check if the image is of sufficient quality for recognition.\n",
    "faces = face_client.detect(\n",
    "    file_content,\n",
    "    detection_model=FaceDetectionModel.DETECTION03,  # The latest detection model.\n",
    "    recognition_model=FaceRecognitionModel.RECOGNITION04,  # The latest recognition model.\n",
    "    return_face_id=True,\n",
    "    return_face_attributes=[FaceAttributeTypeRecognition04.QUALITY_FOR_RECOGNITION]\n",
    ")\n",
    "\n",
    "# Open the image using PIL\n",
    "image = Image.open(image_path)\n",
    "draw = ImageDraw.Draw(image)\n",
    "font = ImageFont.load_default()\n",
    "\n",
    "for face in faces:\n",
    "    # Only take the face if it is of sufficient quality.\n",
    "    if face.face_attributes.quality_for_recognition != QualityForRecognition.LOW:\n",
    "        face_ids.append(face.face_id)\n",
    "        # Store face rectangle for later use\n",
    "        face_rectangles[face.face_id] = face.face_rectangle\n",
    "        # Draw bounding box\n",
    "        rect = face.face_rectangle\n",
    "        left = rect.left\n",
    "        top = rect.top\n",
    "        right = left + rect.width\n",
    "        bottom = top + rect.height\n",
    "        draw.rectangle(((left, top), (right, bottom)), outline=\"red\", width=2)\n",
    "\n",
    "# Identify faces\n",
    "identify_results = face_client.identify_from_large_person_group(\n",
    "    face_ids=face_ids,\n",
    "    large_person_group_id=LARGE_PERSON_GROUP_ID,\n",
    ")\n",
    "print(\"Identifying faces in image\")\n",
    "for identify_result in identify_results:\n",
    "    if identify_result.candidates:\n",
    "        person_id = identify_result.candidates[0].person_id\n",
    "        confidence = identify_result.candidates[0].confidence\n",
    "        print(f\"Person is identified for face ID {identify_result.face_id} in image, with a confidence of {confidence}.\")  # Get topmost confidence score\n",
    "\n",
    "        # Verify faces\n",
    "        verify_result = face_client.verify_from_large_person_group(\n",
    "            face_id=identify_result.face_id,\n",
    "            large_person_group_id=LARGE_PERSON_GROUP_ID,\n",
    "            person_id=person_id,\n",
    "        )\n",
    "        print(f\"Person Identified: {person_id}. Verification result: {verify_result.is_identical}. confidence: {verify_result.confidence}\")\n",
    "\n",
    "        # Draw person ID and confidence on the image\n",
    "        rect = face_rectangles[identify_result.face_id]\n",
    "        left = rect.left\n",
    "        top = rect.top\n",
    "        draw.text((left, top - 10), f\"ID: {person_id}, Conf: {confidence:.2f}\", fill=\"red\", font=font)\n",
    "    else:\n",
    "        print(f\"No person identified for face ID {identify_result.face_id} in image.\")\n",
    "\n",
    "# Save or display the image with bounding boxes and labels\n",
    "image.show()  # To display the image\n",
    "#image.save(\"output_image_with_bounding_boxes_and_labels.jpg\")  # To save the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the large person group\n",
    "face_admin_client.large_person_group.delete(LARGE_PERSON_GROUP_ID)\n",
    "print(f\"The person group {LARGE_PERSON_GROUP_ID} is deleted.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
