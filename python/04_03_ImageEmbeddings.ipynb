{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Image Embeddings\n",
    "\n",
    "Multimodal embeddings APIs of Azure AI Vision let you search for images using text. They turn images and text into coordinates in a multi-dimensional space, matching them based on how closely they relate in meaning. This means you can find images without needing tags or metadata, often getting better search results.\n",
    "\n",
    "To better understand how embeddings work, you can watch my video that explains this in this LinkedIn Video: \n",
    "https://www.linkedin.com/learning/building-rag-solutions-with-azure-ai-foundry-formerly-azure-ai-studio/vector-embeddings-how-words-connect-to-each-other\n",
    "\n",
    "Further Reading:\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-image-retrieval\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/image-retrieval?tabs=python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "azure_computer_vision_endpoint = os.environ[\"AZURE_COMPUTER_VISION_ENDPOINT\"]\n",
    "azure_computer_vision_key = os.environ[\"AZURE_COMPUTER_VISION_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the Vectorize Image API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Function to vectorize an image\n",
    "def vectorize_image(image_source, is_url=True):\n",
    "    # API URL\n",
    "    url = f\"{azure_computer_vision_endpoint}/computervision/retrieval:vectorizeImage?api-version=2024-02-01&model-version=2023-04-15\"\n",
    "\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": azure_computer_vision_key\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        if is_url:\n",
    "            # Set headers for URL\n",
    "            headers[\"Content-Type\"] = \"application/json\"\n",
    "            data = {\n",
    "                \"url\": image_source\n",
    "            }\n",
    "            # Make the request\n",
    "            response = requests.post(url, headers=headers, json=data)\n",
    "        else:\n",
    "            # Read the image file\n",
    "            with open(image_source, \"rb\") as image_file:\n",
    "                image_data = image_file.read()\n",
    "\n",
    "            # Set headers for image file\n",
    "            headers[\"Content-Type\"] = \"application/octet-stream\"\n",
    "            # Make the request\n",
    "            response = requests.post(url, headers=headers, data=image_data)\n",
    "\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "        # Return the response\n",
    "        return response.json()\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus1_result = vectorize_image(\"../data/customclassificationchallenge/bus/bus1.jpeg\", False)\n",
    "print(\"Bus 1: \", bus1_result[\"vector\"])\n",
    "\n",
    "bus2_result = vectorize_image(\"../data/customclassificationchallenge/bus/bus2.jpeg\", False)\n",
    "print(\"Bus 2: \", bus2_result[\"vector\"])\n",
    "\n",
    "japcherry1_result = vectorize_image(\"../data/customclassification/japanese_cherry/japanese_cherry_1.jpg\", False)\n",
    "print(\"Japanese Cherry 1: \", japcherry1_result[\"vector\"])\n",
    "\n",
    "japcherry2_result = vectorize_image(\"../data/customclassification/japanese_cherry/japanese_cherry_2.jpg\", False)\n",
    "print(\"Japanese Cherry 2: \", japcherry2_result[\"vector\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Vector Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    return np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bus 1 vs Bus 2\")\n",
    "print(cosine_similarity(bus1_result[\"vector\"], bus2_result[\"vector\"]))\n",
    "\n",
    "print(\"Bus vs Japanese Cherry\")\n",
    "print(cosine_similarity(bus1_result[\"vector\"], japcherry1_result[\"vector\"]))\n",
    "print(cosine_similarity(bus2_result[\"vector\"], japcherry1_result[\"vector\"]))\n",
    "print(cosine_similarity(bus1_result[\"vector\"], japcherry2_result[\"vector\"]))\n",
    "print(cosine_similarity(bus2_result[\"vector\"], japcherry2_result[\"vector\"]))\n",
    "\n",
    "print(\"Japanese Cherry 1 vs Japanese Cherry 2\")\n",
    "print(cosine_similarity(japcherry1_result[\"vector\"], japcherry2_result[\"vector\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the Vectorize Text API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def vectorize_text(text):\n",
    "    \n",
    "    # API URL\n",
    "    url = f\"{azure_computer_vision_endpoint}/computervision/retrieval:vectorizeText?api-version=2024-02-01&model-version=2023-04-15\"\n",
    "\n",
    "    # Set headers\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Ocp-Apim-Subscription-Key\": azure_computer_vision_key\n",
    "    }\n",
    "\n",
    "    # Set the data payload\n",
    "    data = {\n",
    "        \"text\": text\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Make the request\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "        # Return the JSON response\n",
    "        return response.json()\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"bus\"\n",
    "text_vector = vectorize_text(user_input)\n",
    "print(\"Text: \", user_input)\n",
    "print(cosine_similarity(text_vector[\"vector\"], bus1_result[\"vector\"]))\n",
    "print(cosine_similarity(text_vector[\"vector\"], bus2_result[\"vector\"]))\n",
    "print(cosine_similarity(text_vector[\"vector\"], japcherry1_result[\"vector\"]))\n",
    "print(cosine_similarity(text_vector[\"vector\"], japcherry2_result[\"vector\"]))\n",
    "\n",
    "user_input = \"japanese cherry\"\n",
    "print(\"Text: \", user_input)\n",
    "text_vector = vectorize_text(user_input)\n",
    "print(cosine_similarity(text_vector[\"vector\"], bus1_result[\"vector\"]))\n",
    "print(cosine_similarity(text_vector[\"vector\"], bus2_result[\"vector\"]))\n",
    "print(cosine_similarity(text_vector[\"vector\"], japcherry1_result[\"vector\"]))\n",
    "print(cosine_similarity(text_vector[\"vector\"], japcherry2_result[\"vector\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
