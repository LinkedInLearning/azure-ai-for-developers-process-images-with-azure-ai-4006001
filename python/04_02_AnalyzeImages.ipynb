{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Images using Azure OpenAI\n",
    "\n",
    "Pre-requisites:\n",
    "1. Create Azure OpenAI resource\n",
    "2. Deploy gpt-4 and above model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and Prepare the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a Path object for the image file\n",
    "image_path = Path(\"images/generated_image.jpg\")\n",
    "\n",
    "# Using a context manager to open the file with Path.open()\n",
    "with image_path.open(\"rb\") as image_file:\n",
    "    base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Prepare the image content in the required format for the Azure OpenAI service\n",
    "content_images = [\n",
    "    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "    for base64_image in [base64_image]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncAzureOpenAI\n",
    "\n",
    "# Create the Vision client\n",
    "vision_client = AsyncAzureOpenAI(\n",
    "    api_key=azure_openai_key, \n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint\n",
    ")\n",
    "vision_deployment_name = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: This is a photograph of a domestic cat walking casually down a quiet residential street during what appears to be early morning or late afternoon due to the soft, golden lighting. The cat is mostly white with dark gray and black tabby markings on its head, back, and tail. It has striking green eyes and a focused expression, giving the impression that it is on a mission or exploration.\n",
      "\n",
      "The foreground showcases the textured surface of the asphalt road. In the background, there is a residential neighborhood with houses featuring pitched roofs. A metal fence and gate, a parked car, and a blue trash bin are visible on the right side of the image. On the left, further down the street, there are colorful shrubs with red flowers and a palm tree in the distance, all slightly blurred due to the shallow depth of field. The image captures a tranquil, serene moment in what seems like a suburban environment.\n"
     ]
    }
   ],
   "source": [
    "# Define the user prompt for the image description\n",
    "user_prompt = \"Describe this image in detail.\"\n",
    "\n",
    "# Send a request to the Azure OpenAI service to analyze the image and generate a description\n",
    "response = await vision_client.chat.completions.create(\n",
    "    model=vision_deployment_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": user_prompt,\n",
    "                },\n",
    "                *content_images,  # Include the image content in the request\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=1000,  # Set the maximum number of tokens for the response\n",
    ")\n",
    "\n",
    "# Print the generated description of the image\n",
    "print(\"Response: \" + response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting results similar to Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 1. \"On patrol: the neighborhood guardian is on the move! üêæ\"  \n",
      "2. \"Strutting into Monday like I own the block. üòº\"  \n",
      "3. \"Sunrise strolls and paws on the pavement. ‚òÄÔ∏èüêæ\"  \n",
      "4. \"Keeping an eye on the street‚Äîsecurity at its finest. üêà‚Äç‚¨õ\"  \n",
      "5. \"The queen of this quiet corner takes her morning walk. üëë\"  \n",
      "6. \"Determined and unfazed, as only a cat can be. üòè\"  \n",
      "7. \"Today's forecast: partly curious with a chance of mischief. üò∫\"  \n",
      "8. \"Every street‚Äôs runway needs its own supermodel. üêæ‚ú®\"  \n",
      "9. \"When you‚Äôre the unspoken ruler of the entire neighborhood. üè°\"  \n",
      "10. \"Step aside, humans. This road clearly belongs to me. üö∂‚Äç‚ôÄÔ∏èüêà\"  \n"
     ]
    }
   ],
   "source": [
    "# Define the user prompt for the image description\n",
    "user_prompt = \"Provide me 10 captions for this image.\"\n",
    "\n",
    "# Send a request to the Azure OpenAI service to analyze the image and generate a description\n",
    "response = await vision_client.chat.completions.create(\n",
    "    model=vision_deployment_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": user_prompt,\n",
    "                },\n",
    "                *content_images,  # Include the image content in the request\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=1000,  # Set the maximum number of tokens for the response\n",
    ")\n",
    "\n",
    "# Print the generated description of the image\n",
    "print(\"Response: \" + response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: ```json\n",
      "{\n",
      "    \"description\": \"A gray-and-white cat is walking confidently on a quiet suburban street during a sunny day.\",\n",
      "    \"category\": \"cat\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Define the user prompt for the image description\n",
    "user_prompt = \"\"\"Analyze this image.\n",
    "    Provide response in sample JSON format.\n",
    "    {\n",
    "        \"description\": \"Describe the image in less than 50 words\",\n",
    "        \"category\": cat, dog, or mouse\n",
    "    }\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Send a request to the Azure OpenAI service to analyze the image and generate a description\n",
    "response = await vision_client.chat.completions.create(\n",
    "    model=vision_deployment_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": user_prompt,\n",
    "                },\n",
    "                *content_images,  # Include the image content in the request\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=1000,  # Set the maximum number of tokens for the response\n",
    ")\n",
    "\n",
    "# Print the generated description of the image\n",
    "print(\"Response: \" + response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
