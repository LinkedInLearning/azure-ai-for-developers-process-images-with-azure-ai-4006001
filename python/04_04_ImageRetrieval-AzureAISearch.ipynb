{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Retrieval with Azure AI Search\n",
    "\n",
    "Requirements:\n",
    "1. Azure AI Search - to contain the image embeddings\n",
    "2. Azure Computer Vision - to compute the image and user query (image or text) embeddings\n",
    "3. Azure Storage - to store the raw images\n",
    "\n",
    "Steps:\n",
    "1. Store images in Azure Storage \n",
    "2. Get access to images in Azure Storage\n",
    "3. Create Search index in Azure AI Search\n",
    "4. Generate embeddings and dense captions for images using Azure AI Vision\n",
    "5. Store embeddings and other metadata to Azure AI Search\n",
    "6. Perform a Vector Search in Azure AI Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-storage-blob\n",
    "%pip install azure-search-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "azure_computer_vision_endpoint = os.environ[\"AZURE_COMPUTER_VISION_ENDPOINT\"]\n",
    "azure_computer_vision_key = os.environ[\"AZURE_COMPUTER_VISION_KEY\"]\n",
    "\n",
    "azure_storage_connection_string = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "\n",
    "azure_search_service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "azure_search_service_admin_key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "azure_search_service_index_name = \"az-image-index-001\"\n",
    "azure_search_service_embedding_size=1024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get files from Azure Storage and Store in a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# Initialize the BlobServiceClient with the connection string\n",
    "blob_service_client = BlobServiceClient.from_connection_string(azure_storage_connection_string)\n",
    "\n",
    "# Get the container client\n",
    "container_client = blob_service_client.get_container_client(\"images\")\n",
    "\n",
    "# List blobs in the container and store their URLs, names, and IDs in a collection\n",
    "blobs_collection = []\n",
    "\n",
    "idx = 0\n",
    "try:\n",
    "    blobs_list = container_client.list_blobs()\n",
    "    for blob in blobs_list:\n",
    "        idx += 1\n",
    "        blob_url = f\"{container_client.url}/{blob.name}\"\n",
    "        blobs_collection.append({\"id\": str(idx), \"imageName\": blob.name, \"imageUrl\": blob_url})\n",
    "    print(\"Access to the blob storage was granted.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to access the blob storage: {e}\")\n",
    "\n",
    "# Print the collection\n",
    "print(\"Blobs collection:\")\n",
    "for blob in blobs_collection:\n",
    "    print(blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dense Captions for each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Create an Image Analysis client\n",
    "client = ImageAnalysisClient(\n",
    "    endpoint=azure_computer_vision_endpoint,\n",
    "    credential=AzureKeyCredential(azure_computer_vision_key)\n",
    ")\n",
    "\n",
    "# Get dense captions for each image in the collection and add them to the collection\n",
    "for blob in blobs_collection:\n",
    "\n",
    "    # Get the dense captions for the image. This will be a synchronously (blocking) call.\n",
    "    response = client.analyze_from_url(\n",
    "        image_url=blob[\"imageUrl\"],\n",
    "        visual_features=[VisualFeatures.DENSE_CAPTIONS],\n",
    "        gender_neutral_caption=True,  # Optional (default is False)\n",
    "    )\n",
    "\n",
    "    # Collect all dense captions' text and combine them with a comma separator\n",
    "    dense_captions_text = \", \".join([item['text'] for item in response.dense_captions['values']])\n",
    "\n",
    "    # Add the embeddings to the collection\n",
    "    if response:\n",
    "        blob[\"imageDenseCaptions\"] = dense_captions_text\n",
    "    else:\n",
    "        blob[\"imageDenseCaptions\"] = None\n",
    "\n",
    "# Print the collection\n",
    "print(\"Blobs collection:\")\n",
    "for blob in blobs_collection:\n",
    "    print(blob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Image API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Function to vectorize an image\n",
    "def vectorize_image(image_source, is_url=True):\n",
    "    # API URL\n",
    "    url = f\"{azure_computer_vision_endpoint}/computervision/retrieval:vectorizeImage?api-version=2024-02-01&model-version=2023-04-15\"\n",
    "\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": azure_computer_vision_key\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        if is_url:\n",
    "            # Set headers for URL\n",
    "            headers[\"Content-Type\"] = \"application/json\"\n",
    "            data = {\n",
    "                \"url\": image_source\n",
    "            }\n",
    "            # Make the request\n",
    "            response = requests.post(url, headers=headers, json=data)\n",
    "        else:\n",
    "            # Read the image file\n",
    "            with open(image_source, \"rb\") as image_file:\n",
    "                image_data = image_file.read()\n",
    "\n",
    "            # Set headers for image file\n",
    "            headers[\"Content-Type\"] = \"application/octet-stream\"\n",
    "            # Make the request\n",
    "            response = requests.post(url, headers=headers, data=image_data)\n",
    "\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "        # Return the response\n",
    "        return response.json()\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Embeddings for each Image and Save Collection to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Vectorize each image in the collection and add the embeddings to the collection\n",
    "for blob in blobs_collection:\n",
    "    # Vectorize the image\n",
    "    response = vectorize_image(blob[\"imageUrl\"], is_url=True)\n",
    "\n",
    "    # Add the embeddings to the collection\n",
    "    if response:\n",
    "        blob[\"imageVector\"] = response[\"vector\"]\n",
    "    else:\n",
    "        blob[\"imageVector\"] = None\n",
    "\n",
    "# save the blob collection to a file\n",
    "import json\n",
    "# Save the blob collection to a file\n",
    "output_file = \"blobs_collection.json\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(blobs_collection, file, indent=4)\n",
    "\n",
    "print(f\"Blobs collection saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure AI Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SearchIndex\n",
    ")\n",
    "\n",
    "# Get credential from Azure AI Search Admin key\n",
    "credential = AzureKeyCredential(azure_search_service_admin_key)\n",
    "\n",
    "# Create a search index\n",
    "index_client = SearchIndexClient(\n",
    "  endpoint=azure_search_service_endpoint, \n",
    "  credential=credential)\n",
    "\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"imageName\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"imageUrl\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"imageDenseCaptions\", type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"imageVector\", \n",
    "                type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, \n",
    "                vector_search_dimensions=azure_search_service_embedding_size, \n",
    "                vector_search_profile_name=\"myHnswProfile\"),\n",
    "]\n",
    "\n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(name=\"myHnsw\")\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHnsw\"\n",
    "        )\n",
    "    ] \n",
    ")\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=azure_search_service_index_name, \n",
    "                    fields=fields,\n",
    "                    vector_search=vector_search)\n",
    "\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data into Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from azure.search.documents import SearchIndexingBufferedSender\n",
    "\n",
    "# Load the JSON file\n",
    "file_path = 'blobs_collection.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    documents = json.load(file)\n",
    "\n",
    "# Use SearchIndexingBufferedSender to upload the documents in batches optimized for indexing\n",
    "with SearchIndexingBufferedSender(\n",
    "    endpoint=azure_search_service_endpoint,\n",
    "    index_name=azure_search_service_index_name,\n",
    "    credential=credential,\n",
    ") as batch_client:\n",
    "    # Add upload actions for all documents\n",
    "    batch_client.upload_documents(documents)\n",
    "\n",
    "print(f\"Uploaded {len(documents)} documents in total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Text API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def vectorize_text(text):\n",
    "    \n",
    "    # API URL\n",
    "    url = f\"{azure_computer_vision_endpoint}/computervision/retrieval:vectorizeText?api-version=2024-02-01&model-version=2023-04-15\"\n",
    "\n",
    "    # Set headers\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Ocp-Apim-Subscription-Key\": azure_computer_vision_key\n",
    "    }\n",
    "\n",
    "    # Set the data payload\n",
    "    data = {\n",
    "        \"text\": text\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Make the request\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "        # Return the JSON response\n",
    "        return response.json()\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a Text Search in Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Get credential from Azure AI Search Admin key\n",
    "credential = AzureKeyCredential(azure_search_service_admin_key)\n",
    "search_client = SearchClient(endpoint=azure_search_service_endpoint, \n",
    "                             credential=credential, \n",
    "                             index_name=azure_search_service_index_name)\n",
    "\n",
    "# Get the vector of the query\n",
    "query = \"people working with a laptop\"\n",
    "vectorized_text = vectorize_text(query)\n",
    "vector = vectorized_text[\"vector\"]\n",
    "\n",
    "# display user input\n",
    "print(f\"User Input: {query}\")\n",
    "print(\"************************************\")\n",
    "\n",
    "# Create the VectorizedQuery instance\n",
    "vector_query = VectorizedQuery(\n",
    "    vector=vector, \n",
    "    k_nearest_neighbors=5, \n",
    "    fields=\"imageVector\"\n",
    ")\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"imageName\", \"imageUrl\", \"imageDenseCaptions\"],\n",
    "    top=3\n",
    ")\n",
    "\n",
    "# Process and display the results\n",
    "print(\"Search Results: \")\n",
    "for result in results:\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    image_name = result['imageName']\n",
    "    image_url = result['imageUrl']\n",
    "    image_dense_captions = result['imageDenseCaptions']\n",
    "    print(f\"Image Name: {image_name}, Image URL: {image_url}\")\n",
    "    print(f\"Dense Captions: {image_dense_captions}\")\n",
    "    display(Image(url=image_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a search using an Image in Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Get credential from Azure AI Search Admin key\n",
    "credential = AzureKeyCredential(azure_search_service_admin_key)\n",
    "search_client = SearchClient(endpoint=azure_search_service_endpoint, \n",
    "                             credential=credential, \n",
    "                             index_name=azure_search_service_index_name)\n",
    "\n",
    "# Get the vector of the query\n",
    "query = \"../data/customclassification/test/test_image.jpg\"\n",
    "vectorized_image = vectorize_image(query, is_url=False)\n",
    "vector = vectorized_image[\"vector\"]\n",
    "\n",
    "# display user input\n",
    "print(f\"User Input: {query}\")\n",
    "display(Image(filename=query))\n",
    "print(\"************************************\")\n",
    "\n",
    "# Create the VectorizedQuery instance\n",
    "vector_query = VectorizedQuery(\n",
    "    vector=vector, \n",
    "    k_nearest_neighbors=5, \n",
    "    fields=\"imageVector\"\n",
    ")\n",
    "\n",
    "# Perform the search\n",
    "results = search_client.search(\n",
    "    search_text=None,  \n",
    "    vector_queries=[vector_query],  # Include the vector query here\n",
    "    select=[\"imageName\", \"imageUrl\"],\n",
    "    top=3\n",
    ")\n",
    "\n",
    "# Process and display the results\n",
    "print(\"Search Results: \")\n",
    "for result in results:\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    image_name = result['imageName']\n",
    "    image_url = result['imageUrl']\n",
    "    print(f\"Image Name: {image_name}, Image URL: {image_url}\")\n",
    "    display(Image(url=image_url))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
